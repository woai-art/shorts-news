"""
Twitter Engine Ð´Ð»Ñ Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ð° Ñ‚Ð²Ð¸Ñ‚Ð¾Ð²
"""

import logging
import re
from typing import Dict, List, Any
from urllib.parse import urlparse

# ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ð´Ð»Ñ Ð¿Ð¾Ð´Ð°Ð²Ð»ÐµÐ½Ð¸Ñ Ð¿Ñ€ÐµÐ´ÑƒÐ¿Ñ€ÐµÐ¶Ð´ÐµÐ½Ð¸Ð¹
try:
    from selenium_logging_config import configure_selenium_logging
    configure_selenium_logging()
except ImportError:
    pass

from ..base.source_engine import SourceEngine

logger = logging.getLogger(__name__)


class TwitterEngine(SourceEngine):
    """Ð”Ð²Ð¸Ð¶Ð¾Ðº Ð´Ð»Ñ Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ð° Twitter/X"""
    
    def _get_source_name(self) -> str:
        """Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ°"""
        return "TWITTER"
    
    def can_handle(self, url: str) -> bool:
        """ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÑ‚, Ð¼Ð¾Ð¶ÐµÑ‚ Ð»Ð¸ Ð´Ð²Ð¸Ð¶Ð¾Ðº Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ URL"""
        try:
            parsed = urlparse(url)
            domain = parsed.netloc.lower()
            return domain in self._get_supported_domains()
        except Exception:
            return False
    
    def parse_url(self, url: str, driver=None) -> Dict[str, Any]:
        """
        ÐŸÐ°Ñ€ÑÐ¸Ñ‚ Twitter URL Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÑ Selenium
        """
        logger.info(f"ðŸ” ÐŸÐ°Ñ€ÑÐ¸Ð½Ð³ Twitter URL: {url[:50]}...")
        
        try:
            # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Selenium Ð´Ð»Ñ Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ð° Twitter
            logger.info("ðŸ” Selenium Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³ Ð´Ð»Ñ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚Ð°...")
            selenium_result = self._parse_twitter_selenium(url)
            
            if selenium_result and selenium_result.get('title'):
                logger.info(f"âœ… Selenium Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³ ÑƒÑÐ¿ÐµÑˆÐµÐ½: {selenium_result['title'][:50]}...")
                logger.info(f"ðŸ“„ Selenium ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚: {len(selenium_result.get('content', ''))} ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð²")
                
                return {
                    'title': selenium_result.get('title', ''),
                    'description': selenium_result.get('description', ''),
                    'content': selenium_result.get('content', ''),
                    'images': selenium_result.get('images', []),
                    'videos': selenium_result.get('videos', []),
                    'published': selenium_result.get('published', ''),
                    'username': selenium_result.get('username', ''),  # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ username
                    'avatar_url': selenium_result.get('avatar_url', ''), # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ URL Ð°Ð²Ð°Ñ‚Ð°Ñ€Ð°
                    'source': 'TWITTER',
                    'content_type': 'social_media_post'
                }
            else:
                logger.warning("âŒ Selenium Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³ Ð½Ðµ ÑƒÐ´Ð°Ð»ÑÑ, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ fallback")
                return self._get_fallback_content()
                
        except Exception as e:
            logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ð° Twitter URL: {e}")
            import traceback
            logger.error(f"âŒ Traceback: {traceback.format_exc()}")
            return self._get_fallback_content()
    
    def extract_media(self, url: str, content: Dict[str, Any]) -> Dict[str, Any]:
        """Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ Ð¼ÐµÐ´Ð¸Ð° Ð¸Ð· ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚Ð°"""
        return {
            'images': content.get('images', []),
            'videos': content.get('videos', [])
        }
    
    def validate_content(self, content: Dict[str, Any]) -> bool:
        """Ð’Ð°Ð»Ð¸Ð´Ð¸Ñ€ÑƒÐµÑ‚ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚"""
        title = content.get('title', '')
        content_text = content.get('content', '')
        
        # Ð”Ð»Ñ Twitter Ð´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð¸Ð¼ÐµÑ‚ÑŒ Ð»Ð¸Ð±Ð¾ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº, Ð»Ð¸Ð±Ð¾ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚
        if not title and not content_text:
            logger.warning("âŒ Twitter: Ð½ÐµÑ‚ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ° Ð¸ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚Ð°")
            return False
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð½Ð° Ð±Ð»Ð¾ÐºÐ¸Ñ€Ð¾Ð²ÐºÑƒ/ÐºÐ°Ð¿Ñ‡Ñƒ
        if self._is_blocked_content(content_text):
            logger.warning("âŒ Twitter: ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚ Ð·Ð°Ð±Ð»Ð¾ÐºÐ¸Ñ€Ð¾Ð²Ð°Ð½")
            return False
        
        logger.info(f"âœ… Twitter ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚ Ð²Ð°Ð»Ð¸Ð´ÐµÐ½: title={bool(title)}, content={len(content_text)} ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð²")
        return True
    
    def _parse_twitter_selenium(self, url: str) -> Dict[str, Any]:
        """Selenium Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³ Twitter Ð´Ð»Ñ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚Ð°"""
        try:
            from selenium import webdriver
            from selenium.webdriver.chrome.options import Options
            from selenium.webdriver.common.by import By
            from selenium.webdriver.support.ui import WebDriverWait
            from selenium.webdriver.support import expected_conditions as EC
            from bs4 import BeautifulSoup
            import time
            
            # ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Chrome
            chrome_options = Options()
            chrome_options.add_argument('--headless')
            chrome_options.add_argument('--no-sandbox')
            chrome_options.add_argument('--disable-dev-shm-usage')
            chrome_options.add_argument('--disable-gpu')
            chrome_options.add_argument('--disable-gpu-sandbox')
            chrome_options.add_argument('--disable-software-rasterizer')
            chrome_options.add_argument('--disable-webgl')
            chrome_options.add_argument('--disable-webgl2')
            chrome_options.add_argument('--disable-3d-apis')
            chrome_options.add_argument('--disable-accelerated-2d-canvas')
            chrome_options.add_argument('--disable-accelerated-jpeg-decoding')
            chrome_options.add_argument('--disable-accelerated-mjpeg-decode')
            chrome_options.add_argument('--disable-accelerated-video-decode')
            chrome_options.add_argument('--disable-background-timer-throttling')
            chrome_options.add_argument('--disable-backgrounding-occluded-windows')
            chrome_options.add_argument('--disable-renderer-backgrounding')
            chrome_options.add_argument('--disable-features=TranslateUI')
            chrome_options.add_argument('--disable-ipc-flooding-protection')
            chrome_options.add_argument('--window-size=1920,1080')
            chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36')
            chrome_options.add_argument('--log-level=3')  # Ð¢Ð¾Ð»ÑŒÐºÐ¾ ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¾ÑˆÐ¸Ð±ÐºÐ¸
            chrome_options.add_experimental_option('excludeSwitches', ['enable-logging'])
            chrome_options.add_experimental_option('useAutomationExtension', False)
            
            driver = webdriver.Chrome(options=chrome_options)
            
            try:
                driver.get(url)
                time.sleep(8)  # Ð£Ð²ÐµÐ»Ð¸Ñ‡Ð¸Ð»Ð¸ Ð²Ñ€ÐµÐ¼Ñ Ð¾Ð¶Ð¸Ð´Ð°Ð½Ð¸Ñ Ð´Ð»Ñ Ð´Ð¸Ð½Ð°Ð¼Ð¸Ñ‡ÐµÑÐºÐ¾Ð¹ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸
                
                # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ HTML
                html = driver.page_source
                soup = BeautifulSoup(html, 'html.parser')
                
                # ÐžÑ‚Ð»Ð°Ð´Ð¾Ñ‡Ð½Ð°Ñ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ
                logger.info(f"ðŸ“„ HTML Ð´Ð»Ð¸Ð½Ð°: {len(html)} ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð²")
                
                # Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ðµ Ð¾Ð¶Ð¸Ð´Ð°Ð½Ð¸Ðµ Ð´Ð»Ñ Ð´Ð¸Ð½Ð°Ð¼Ð¸Ñ‡ÐµÑÐºÐ¾Ð³Ð¾ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚Ð°
                time.sleep(3)
                
                # Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº (Ñ‚ÐµÐºÑÑ‚ Ñ‚Ð²Ð¸Ñ‚Ð°) - Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð»Ð¾Ð³Ð¸ÐºÑƒ Ð¸Ð· ÑÑ‚Ð°Ñ€Ð¾Ð³Ð¾ ÐºÐ¾Ð´Ð°
                title = ""
                main_text_selectors = [
                    '[data-testid="tweetText"]',
                    'article[role="article"] div[data-testid="tweetText"]',
                    'article div[lang] span',
                    # ÐÐ¾Ð²Ñ‹Ðµ ÑÐµÐ»ÐµÐºÑ‚Ð¾Ñ€Ñ‹ Ð´Ð»Ñ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ð¾Ð³Ð¾ Twitter
                    'div[data-testid="tweet"] span[dir="auto"]',
                    'article span[dir="auto"]',
                    'div[lang] span',
                    'div[data-testid="tweetText"] span',
                    # Ð£Ð½Ð¸Ð²ÐµÑ€ÑÐ°Ð»ÑŒÐ½Ñ‹Ðµ ÑÐµÐ»ÐµÐºÑ‚Ð¾Ñ€Ñ‹
                    'article p',
                    'article div[lang]',
                    'div[data-testid="tweet"] div[lang]'
                ]
                
                for selector in main_text_selectors:
                    try:
                        elements = driver.find_elements(By.CSS_SELECTOR, selector)
                        if elements:
                            # Ð¡Ð¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð²ÐµÑÑŒ Ñ‚ÐµÐºÑÑ‚ Ð¸ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€ÑƒÐµÐ¼
                            all_text = ' '.join([elem.text for elem in elements if elem.text.strip()])
                            logger.info(f"ðŸ” Ð˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚ ({len(all_text)} ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð²): {all_text[:200]}...")
                            
                            # Ð•ÑÐ»Ð¸ Ñ‚ÐµÐºÑÑ‚ Ð´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð´Ð»Ð¸Ð½Ð½Ñ‹Ð¹, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ ÐµÐ³Ð¾ ÐºÐ°Ðº ÐµÑÑ‚ÑŒ
                            if len(all_text) > 50:
                                # ÐŸÑ€Ð¾ÑÑ‚Ð°Ñ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸Ñ Ð±ÐµÐ· Ñ€Ð°Ð·Ð±Ð¸ÐµÐ½Ð¸Ñ Ð½Ð° ÑÑ‚Ñ€Ð¾ÐºÐ¸
                                filtered_text = all_text
                                
                                # Ð£Ð±Ð¸Ñ€Ð°ÐµÐ¼ ÑÐ»ÑƒÐ¶ÐµÐ±Ð½ÑƒÑŽ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ
                                lines_to_remove = [
                                    'OSINTdefender', '@sentdefender', 'ago', 'reply', 'retweet', 
                                    'show this thread', 'Show this thread', 'Show this thread'
                                ]
                                
                                for remove_text in lines_to_remove:
                                    if remove_text in filtered_text:
                                        # Ð£Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÐµÑÐ»Ð¸ ÑÑ‚Ð¾ Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð°Ñ ÑÑ‚Ñ€Ð¾ÐºÐ°
                                        filtered_text = filtered_text.replace(f'\n{remove_text}\n', '\n')
                                        filtered_text = filtered_text.replace(f'{remove_text}\n', '')
                                        filtered_text = filtered_text.replace(f'\n{remove_text}', '')
                                
                                title = filtered_text.strip()
                                logger.info(f"âœ… ÐžÑ‚Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚ ({len(title)} ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð²): {title[:200]}...")
                                
                                if len(title) > 30:  # Ð”Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ñ‚ÐµÐºÑÑ‚Ð°
                                    break
                            else:
                                # Ð¡Ñ‚Ð°Ñ€Ð°Ñ Ð»Ð¾Ð³Ð¸ÐºÐ° Ð´Ð»Ñ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ñ… Ñ‚ÐµÐºÑÑ‚Ð¾Ð²
                                lines = all_text.split('\n')
                                valid_lines = []
                                
                                for line in lines:
                                    line = line.strip()
                                    # ÐŸÑ€Ð¾Ð¿ÑƒÑÐºÐ°ÐµÐ¼ ÑÑ‚Ñ€Ð¾ÐºÐ¸ Ñ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ñ†Ð¸Ñ„Ñ€Ð°Ð¼Ð¸, Ð¾Ñ‡ÐµÐ½ÑŒ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ðµ ÑÑ‚Ñ€Ð¾ÐºÐ¸, ÑÐ»ÑƒÐ¶ÐµÐ±Ð½ÑƒÑŽ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ
                                    if (line and len(line) > 5 and  # ÐœÐ¸Ð½Ð¸Ð¼ÑƒÐ¼ 5 ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð²
                                        not line.isdigit() and  # ÐÐµ Ñ‡Ð¸ÑÐ»Ð¾Ð²Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ
                                        not line.startswith('@') and  # ÐÐµ ÑƒÐ¿Ð¾Ð¼Ð¸Ð½Ð°Ð½Ð¸Ñ
                                        'ago' not in line.lower() and
                                        'reply' not in line.lower() and
                                        'retweet' not in line.lower() and
                                        'show this thread' not in line.lower()):
                                        valid_lines.append(line)
                                
                                if valid_lines:
                                    title = ' '.join(valid_lines)
                                    if len(title) > 10:  # Ð”Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ñ‚ÐµÐºÑÑ‚Ð°
                                        break
                    except Exception as e:
                        logger.debug(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ð¸ Ñ‚ÐµÐºÑÑ‚Ð° ÑÐµÐ»ÐµÐºÑ‚Ð¾Ñ€Ð¾Ð¼ {selector}: {e}")
                        continue
                
                # Ð•ÑÐ»Ð¸ Ð½Ðµ Ð½Ð°ÑˆÐ»Ð¸ Ñ‡ÐµÑ€ÐµÐ· ÑÐµÐ»ÐµÐºÑ‚Ð¾Ñ€Ñ‹, Ð¸Ñ‰ÐµÐ¼ Ð¿Ð¾ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ðµ
                if not title:
                    # Ð˜Ñ‰ÐµÐ¼ Ð² article Ñ lang Ð°Ñ‚Ñ€Ð¸Ð±ÑƒÑ‚Ð¾Ð¼
                    articles = soup.find_all('article')
                    for article in articles:
                        lang_elem = article.find(attrs={'lang': True})
                        if lang_elem:
                            title = lang_elem.get_text().strip()
                            break
                
                # Ð•ÑÐ»Ð¸ Ð²ÑÐµ ÐµÑ‰Ðµ Ð½Ðµ Ð½Ð°ÑˆÐ»Ð¸, Ð¸Ñ‰ÐµÐ¼ Ð»ÑŽÐ±Ð¾Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð² Ñ‚Ð²Ð¸Ñ‚Ðµ
                if not title:
                    # Ð˜Ñ‰ÐµÐ¼ div Ñ data-testid="tweet"
                    tweet_divs = soup.find_all('div', {'data-testid': 'tweet'})
                    for tweet_div in tweet_divs:
                        # Ð˜Ñ‰ÐµÐ¼ Ñ‚ÐµÐºÑÑ‚ Ð² Ð´Ð¾Ñ‡ÐµÑ€Ð½Ð¸Ñ… ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ð°Ñ…
                        text_elements = tweet_div.find_all(['div', 'span', 'p'], string=True)
                        for elem in text_elements:
                            text = elem.get_text().strip()
                            if len(text) > 10 and not any(skip in text.lower() for skip in ['follow', 'retweet', 'like', 'reply', 'share']):
                                title = text
                                break
                        if title:
                            break
                
                # Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ (Ñ‚Ð¾ Ð¶Ðµ Ñ‡Ñ‚Ð¾ Ð¸ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº Ð´Ð»Ñ Ñ‚Ð²Ð¸Ñ‚Ð¾Ð²)
                description = title
                
                # Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ Ð´Ð°Ñ‚Ñƒ Ð¿ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ†Ð¸Ð¸
                published = ""
                date_selectors = [
                    'time[datetime]',
                    '[data-testid="tweet"] time',
                    'article time'
                ]
                
                for selector in date_selectors:
                    date_elem = soup.select_one(selector)
                    if date_elem:
                        published = date_elem.get('datetime', '').strip()
                        break
                
                # Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ Ð°Ð²Ñ‚Ð¾Ñ€Ð° Ð´Ð»Ñ Ð°Ð²Ð°Ñ‚Ð°Ñ€ÐºÐ¸, Ð½Ð¾ Ð½Ðµ Ð¿ÐµÑ€ÐµÐ¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº
                author = "Twitter User"  # Ð‘Ð°Ð·Ð¾Ð²Ð¾Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ
                username = ""  # Ð”Ð»Ñ Ð°Ð²Ð°Ñ‚Ð°Ñ€ÐºÐ¸
                try:
                    # Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ Ð°Ð²Ñ‚Ð¾Ñ€Ð° Ð¸Ð· URL
                    import re
                    username_match = re.search(r'(?:twitter\.com|x\.com)/([^/]+)', url)
                    if username_match:
                        author = username_match.group(1)
                        username = author  # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ username Ð´Ð»Ñ Ð°Ð²Ð°Ñ‚Ð°Ñ€ÐºÐ¸
                        logger.info(f"ðŸ¦ Ð˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½ username: @{username}")
                    else:
                        logger.warning(f"âŒ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¸Ð·Ð²Ð»ÐµÑ‡ÑŒ username Ð¸Ð· URL: {url}")
                except Exception as e:
                    logger.warning(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ñ username: {e}")

                # Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ URL Ð°Ð²Ð°Ñ‚Ð°Ñ€Ð°
                avatar_url = ""
                try:
                    # Ð˜Ñ‰ÐµÐ¼ Ð°Ð²Ð°Ñ‚Ð°Ñ€ Ð¿Ð¾ ÑÐµÐ»ÐµÐºÑ‚Ð¾Ñ€Ñƒ, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ñ‡Ð°ÑÑ‚Ð¾ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ Ð´Ð»Ñ Ð°Ð²Ð°Ñ‚Ð°Ñ€Ð¾Ðº Ð² Ñ‚Ð²Ð¸Ñ‚Ð°Ñ…
                    avatar_selectors = [
                        'div[data-testid="tweet"] a[role="link"] img',
                        'article[data-testid="tweet"] div[data-testid^="UserAvatar-Container"] img',
                        'div[data-testid="tweet"] img[alt$="profile image"]'
                    ]
                    for selector in avatar_selectors:
                        avatar_img = soup.select_one(selector)
                        if avatar_img and 'profile_images' in avatar_img.get('src', ''):
                            avatar_url = avatar_img['src'].replace('_normal', '_400x400')
                            logger.info(f"ðŸ–¼ï¸ ÐÐ°Ð¹Ð´ÐµÐ½ URL Ð°Ð²Ð°Ñ‚Ð°Ñ€Ð°: {avatar_url}")
                            break
                except Exception as e:
                    logger.warning(f"âš ï¸ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¸Ð·Ð²Ð»ÐµÑ‡ÑŒ URL Ð°Ð²Ð°Ñ‚Ð°Ñ€Ð°: {e}")
                
                # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº Ñ‚Ð²Ð¸Ñ‚Ð° - LLM ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ Ð±Ñ€Ð¾ÑÐºÐ¸Ð¹ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº
                short_title = title
                
                # ÐšÐ¾Ð½Ñ‚ÐµÐ½Ñ‚ = Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚ Ñ‚Ð²Ð¸Ñ‚Ð°
                content_text = title
                
                # Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ Ð¼ÐµÐ´Ð¸Ð° Ñ„Ð°Ð¹Ð»Ñ‹ (Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ, GIF, Ð²Ð¸Ð´ÐµÐ¾) - ÐºÐ°Ðº Ð² ÑÑ‚Ð°Ñ€Ð¾Ð¼ ÐºÐ¾Ð´Ðµ
                images = []
                videos = []
                try:
                    # Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð¸ GIF
                    image_selectors = [
                        '[data-testid="tweetPhoto"] img',
                        'article[data-testid="tweet"] img[alt="Image"]',
                        'div[data-testid="card.wrapper"] img',
                        'article img[src*="media"]'
                    ]
                    for selector in image_selectors:
                        img_elements = driver.find_elements(By.CSS_SELECTOR, selector)
                        for img in img_elements:
                            src = img.get_attribute('src')
                            if src and src not in images:
                                # Clean up the URL
                                if 'pbs.twimg.com' in src:
                                    if 'format=gif' in src:
                                        src = src.replace('format=gif', 'format=jpg')
                                    if 'name=medium' in src:
                                        src = src.replace('name=medium', 'name=large')
                                    elif 'name=small' in src:
                                        src = src.replace('name=small', 'name=large')
                                
                                if src not in images:
                                    images.append(src)
                            if len(images) >= 3:
                                break
                        if len(images) >= 3:
                            break
                    
                    # Ð’Ð¸Ð´ÐµÐ¾ - ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð½Ñ‹Ð¹ Ð¿Ð¾Ð¸ÑÐº
                    video_selectors = [
                        '[data-testid="videoPlayer"] video',
                        '[data-testid="videoComponent"] video',
                        'video[poster*="amplify_video"]',
                        'video[src*=".mp4"]',
                        '[role="button"] video'
                    ]
                    
                    for selector in video_selectors:
                        video_elements = driver.find_elements(By.CSS_SELECTOR, selector)
                        for video in video_elements[:3-len(images)]:
                            # ÐŸÑ€Ð¾Ð±ÑƒÐµÐ¼ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð¿Ñ€ÑÐ¼ÑƒÑŽ ÑÑÑ‹Ð»ÐºÑƒ Ð½Ð° Ð²Ð¸Ð´ÐµÐ¾
                            src = video.get_attribute('src')
                            poster = video.get_attribute('poster')
                            
                            if src and '.mp4' in src and src not in videos:
                                videos.append(src)
                                logger.info(f"ðŸŽ¬ ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ Ð²Ð¸Ð´ÐµÐ¾: {src[:50]}...")
                            elif poster and poster not in images:
                                # Ð•ÑÐ»Ð¸ ÐµÑÑ‚ÑŒ poster, Ð¿Ñ€Ð¾Ð±ÑƒÐµÐ¼ Ð¸Ð·Ð²Ð»ÐµÑ‡ÑŒ Ð²Ð¸Ð´ÐµÐ¾ Ð¸Ð· Ð½ÐµÐ³Ð¾
                                if 'amplify_video_thumb' in poster:
                                    # ÐŸÑ€Ð¾Ð±ÑƒÐµÐ¼ Ð·Ð°Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ thumb Ð½Ð° Ð²Ð¸Ð´ÐµÐ¾
                                    video_url = poster.replace('amplify_video_thumb', 'amplify_video').replace('/img/', '/vid/').replace('.jpg', '.mp4')
                                    if video_url not in videos:
                                        videos.append(video_url)
                                        logger.info(f"ðŸŽ¬ ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ Ð¿Ð¾Ñ‚ÐµÐ½Ñ†Ð¸Ð°Ð»ÑŒÐ½Ð¾Ðµ Ð²Ð¸Ð´ÐµÐ¾: {video_url[:50]}...")
                                if poster not in images:
                                    images.append(poster)
                        
                        if len(videos) >= 3:
                            break
                    
                    # ÐŸÐ¾Ð¸ÑÐº Ð²Ð¸Ð´ÐµÐ¾ Ñ‡ÐµÑ€ÐµÐ· meta Ñ‚ÐµÐ³Ð¸
                    try:
                        meta_video_selectors = [
                            'meta[property="og:video"]',
                            'meta[property="og:video:url"]',
                            'meta[property="twitter:player:stream"]',
                            'meta[name="twitter:player:stream"]'
                        ]
                        
                        for selector in meta_video_selectors:
                            meta_elements = driver.find_elements(By.CSS_SELECTOR, selector)
                            for meta in meta_elements:
                                content = meta.get_attribute('content')
                                if content and content not in videos and ('.mp4' in content or 'video' in content):
                                    videos.append(content)
                                    logger.info(f"ðŸŽ¬ ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ Ð²Ð¸Ð´ÐµÐ¾ Ñ‡ÐµÑ€ÐµÐ· meta: {content[:50]}...")
                                    break
                    except Exception as e:
                        logger.debug(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð¸ÑÐºÐ° Ð²Ð¸Ð´ÐµÐ¾ Ñ‡ÐµÑ€ÐµÐ· meta: {e}")
                    
                    # Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¿Ð¾Ð¸ÑÐº GIF Ð² Twitter
                    gif_elements = driver.find_elements(By.CSS_SELECTOR, 'video[poster*="gif"], img[src*="gif"]')
                    for gif in gif_elements[:3-len(images)]:
                        src = gif.get_attribute('src') or gif.get_attribute('poster')
                        if src and src not in images:
                            images.append(src)
                            
                except Exception as e:
                    logger.warning(f"âš ï¸ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ñ Ð¼ÐµÐ´Ð¸Ð° Ð¸Ð· Twitter: {e}")
                    pass
                
                # Ð£Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð´ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚Ñ‹
                images = list(dict.fromkeys(images))
                videos = list(dict.fromkeys(videos))
                
                logger.info(f"ðŸ“ Twitter Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³: Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº='{short_title[:50]}...', ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚={len(content_text)} ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð², Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ={len(images)}, Ð²Ð¸Ð´ÐµÐ¾={len(videos)}")
                
                return {
                    'title': short_title,  # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ð¹ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº
                    'description': description,
                    'content': content_text,
                    'published': published,
                    'images': images,
                    'videos': videos,
                    'username': username,  # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ username Ð´Ð»Ñ Ð°Ð²Ð°Ñ‚Ð°Ñ€ÐºÐ¸
                    'avatar_url': avatar_url, # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ URL Ð°Ð²Ð°Ñ‚Ð°Ñ€Ð°
                    'source': 'TWITTER',
                    'content_type': 'social_media_post'
                }
                
            finally:
                driver.quit()
            
        except Exception as e:
            logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Selenium Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ð° Twitter: {e}")
            import traceback
            logger.error(f"âŒ Traceback: {traceback.format_exc()}")
            return {}
    
    def _is_blocked_content(self, content: str) -> bool:
        """ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÑ‚, Ð·Ð°Ð±Ð»Ð¾ÐºÐ¸Ñ€Ð¾Ð²Ð°Ð½ Ð»Ð¸ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚"""
        if not content:
            return False
        
        blocked_indicators = [
            'something went wrong',
            'try again',
            'privacy related extensions',
            'disable them and try again',
            'this page is not available',
            'tweet unavailable',
            'tweet not found',
            'don\'t fret',
            'give it another shot'
        ]
        
        content_lower = content.lower()
        for indicator in blocked_indicators:
            if indicator in content_lower:
                return True
        
        return False
    
    def _get_fallback_content(self) -> Dict[str, Any]:
        """Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ fallback ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚"""
        return {
            'title': 'Twitter Post',
            'description': 'Twitter post content unavailable',
            'content': 'Content could not be parsed from Twitter',
            'images': [],
            'videos': [],
            'published': '',
            'source': 'TWITTER',
            'content_type': 'social_media_post'
        }
    
    def _get_supported_domains(self) -> List[str]:
        """Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÐ¼Ñ‹Ðµ Ð´Ð¾Ð¼ÐµÐ½Ñ‹"""
        return ['x.com', 'www.x.com', 'twitter.com', 'www.twitter.com']
