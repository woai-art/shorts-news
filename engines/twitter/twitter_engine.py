"""
Twitter Engine –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ç–≤–∏—Ç–æ–≤
"""

import logging
import re
from typing import Dict, List, Any
from urllib.parse import urlparse

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –ø–æ–¥–∞–≤–ª–µ–Ω–∏—è –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π
try:
    from selenium_logging_config import configure_selenium_logging
    configure_selenium_logging()
except ImportError:
    pass

from ..base.source_engine import SourceEngine

logger = logging.getLogger(__name__)


class TwitterEngine(SourceEngine):
    """–î–≤–∏–∂–æ–∫ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ Twitter/X"""
    
    def _get_source_name(self) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∞"""
        return "TWITTER"
    
    def can_handle(self, url: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –º–æ–∂–µ—Ç –ª–∏ –¥–≤–∏–∂–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å URL"""
        try:
            parsed = urlparse(url)
            domain = parsed.netloc.lower()
            return domain in self._get_supported_domains()
        except Exception:
            return False
    
    def parse_url(self, url: str, driver=None) -> Dict[str, Any]:
        """
        –ü–∞—Ä—Å–∏—Ç Twitter URL –∏—Å–ø–æ–ª—å–∑—É—è Selenium
        """
        logger.info(f"üîç –ü–∞—Ä—Å–∏–Ω–≥ Twitter URL: {url[:50]}...")
        
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º Selenium –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ Twitter
            logger.info("üîç Selenium –ø–∞—Ä—Å–∏–Ω–≥ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞...")
            selenium_result = self._parse_twitter_selenium(url)
            
            if selenium_result and selenium_result.get('title'):
                logger.info(f"‚úÖ Selenium –ø–∞—Ä—Å–∏–Ω–≥ —É—Å–ø–µ—à–µ–Ω: {selenium_result['title'][:50]}...")
                logger.info(f"üìÑ Selenium –∫–æ–Ω—Ç–µ–Ω—Ç: {len(selenium_result.get('content', ''))} —Å–∏–º–≤–æ–ª–æ–≤")
                
                return {
                    'title': selenium_result.get('title', ''),
                    'description': selenium_result.get('description', ''),
                    'content': selenium_result.get('content', ''),
                    'images': selenium_result.get('images', []),
                    'videos': selenium_result.get('videos', []),
                    'published': selenium_result.get('published', ''),
                    'username': selenium_result.get('username', ''),  # –î–æ–±–∞–≤–ª—è–µ–º username
                    'avatar_url': selenium_result.get('avatar_url', ''), # –î–æ–±–∞–≤–ª—è–µ–º URL –∞–≤–∞—Ç–∞—Ä–∞
                    'source': 'TWITTER',
                    'content_type': 'social_media_post'
                }
            else:
                logger.warning("‚ùå Selenium –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ —É–¥–∞–ª—Å—è, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback")
                return self._get_fallback_content()
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ Twitter URL: {e}")
            import traceback
            logger.error(f"‚ùå Traceback: {traceback.format_exc()}")
            return self._get_fallback_content()
    
    def extract_media(self, url: str, content: Dict[str, Any]) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –º–µ–¥–∏–∞ –∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        return {
            'images': content.get('images', []),
            'videos': content.get('videos', [])
        }
    
    def validate_content(self, content: Dict[str, Any]) -> bool:
        """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç"""
        title = content.get('title', '')
        content_text = content.get('content', '')
        
        # –î–ª—è Twitter –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏–º–µ—Ç—å –ª–∏–±–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫, –ª–∏–±–æ –∫–æ–Ω—Ç–µ–Ω—Ç
        if not title and not content_text:
            logger.warning("‚ùå Twitter: –Ω–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞")
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫—É/–∫–∞–ø—á—É
        if self._is_blocked_content(content_text):
            logger.warning("‚ùå Twitter: –∫–æ–Ω—Ç–µ–Ω—Ç –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω")
            return False
        
        logger.info(f"‚úÖ Twitter –∫–æ–Ω—Ç–µ–Ω—Ç –≤–∞–ª–∏–¥–µ–Ω: title={bool(title)}, content={len(content_text)} —Å–∏–º–≤–æ–ª–æ–≤")
        return True
    
    def _parse_twitter_selenium(self, url: str) -> Dict[str, Any]:
        """Selenium –ø–∞—Ä—Å–∏–Ω–≥ Twitter –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        try:
            from selenium import webdriver
            from selenium.webdriver.chrome.options import Options
            from selenium.webdriver.common.by import By
            from selenium.webdriver.support.ui import WebDriverWait
            from selenium.webdriver.support import expected_conditions as EC
            from bs4 import BeautifulSoup
            import time
            
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Chrome
            chrome_options = Options()
            chrome_options.add_argument('--headless')
            chrome_options.add_argument('--no-sandbox')
            chrome_options.add_argument('--disable-dev-shm-usage')
            chrome_options.add_argument('--disable-gpu')
            chrome_options.add_argument('--disable-gpu-sandbox')
            chrome_options.add_argument('--disable-software-rasterizer')
            chrome_options.add_argument('--disable-webgl')
            chrome_options.add_argument('--disable-webgl2')
            chrome_options.add_argument('--disable-3d-apis')
            chrome_options.add_argument('--disable-accelerated-2d-canvas')
            chrome_options.add_argument('--disable-accelerated-jpeg-decoding')
            chrome_options.add_argument('--disable-accelerated-mjpeg-decode')
            chrome_options.add_argument('--disable-accelerated-video-decode')
            chrome_options.add_argument('--disable-background-timer-throttling')
            chrome_options.add_argument('--disable-backgrounding-occluded-windows')
            chrome_options.add_argument('--disable-renderer-backgrounding')
            chrome_options.add_argument('--disable-features=TranslateUI')
            chrome_options.add_argument('--disable-ipc-flooding-protection')
            chrome_options.add_argument('--window-size=1920,1080')
            chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36')
            chrome_options.add_argument('--log-level=3')  # –¢–æ–ª—å–∫–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏
            chrome_options.add_experimental_option('excludeSwitches', ['enable-logging'])
            chrome_options.add_experimental_option('useAutomationExtension', False)
            
            driver = webdriver.Chrome(options=chrome_options)
            
            try:
                driver.get(url)
                time.sleep(8)  # –£–≤–µ–ª–∏—á–∏–ª–∏ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
                
                # –ü–æ–ª—É—á–∞–µ–º HTML
                html = driver.page_source
                soup = BeautifulSoup(html, 'html.parser')
                
                # –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
                logger.info(f"üìÑ HTML –¥–ª–∏–Ω–∞: {len(html)} —Å–∏–º–≤–æ–ª–æ–≤")
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –æ–∂–∏–¥–∞–Ω–∏–µ –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                time.sleep(3)
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ (—Ç–µ–∫—Å—Ç —Ç–≤–∏—Ç–∞) - –∏—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–≥–∏–∫—É –∏–∑ —Å—Ç–∞—Ä–æ–≥–æ –∫–æ–¥–∞
                title = ""
                main_text_selectors = [
                    '[data-testid="tweetText"]',
                    'article[role="article"] div[data-testid="tweetText"]',
                    'article div[lang] span',
                    # –ù–æ–≤—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ Twitter
                    'div[data-testid="tweet"] span[dir="auto"]',
                    'article span[dir="auto"]',
                    'div[lang] span',
                    'div[data-testid="tweetText"] span',
                    # –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã
                    'article p',
                    'article div[lang]',
                    'div[data-testid="tweet"] div[lang]'
                ]
                
                for selector in main_text_selectors:
                    try:
                        elements = driver.find_elements(By.CSS_SELECTOR, selector)
                        if elements:
                            # –°–æ–±–∏—Ä–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç –∏ —Ñ–∏–ª—å—Ç—Ä—É–µ–º
                            all_text = ' '.join([elem.text for elem in elements if elem.text.strip()])
                            logger.info(f"üîç –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç ({len(all_text)} —Å–∏–º–≤–æ–ª–æ–≤): {all_text[:200]}...")
                            
                            # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª–∏–Ω–Ω—ã–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ –∫–∞–∫ –µ—Å—Ç—å
                            if len(all_text) > 50:
                                # –ü—Ä–æ—Å—Ç–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –±–µ–∑ —Ä–∞–∑–±–∏–µ–Ω–∏—è –Ω–∞ —Å—Ç—Ä–æ–∫–∏
                                filtered_text = all_text
                                
                                # –£–±–∏—Ä–∞–µ–º —Å–ª—É–∂–µ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
                                lines_to_remove = [
                                    'OSINTdefender', '@sentdefender', 'ago', 'reply', 'retweet', 
                                    'show this thread', 'Show this thread', 'Show this thread'
                                ]
                                
                                for remove_text in lines_to_remove:
                                    if remove_text in filtered_text:
                                        # –£–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ –æ—Ç–¥–µ–ª—å–Ω–∞—è —Å—Ç—Ä–æ–∫–∞
                                        filtered_text = filtered_text.replace(f'\n{remove_text}\n', '\n')
                                        filtered_text = filtered_text.replace(f'{remove_text}\n', '')
                                        filtered_text = filtered_text.replace(f'\n{remove_text}', '')
                                
                                title = filtered_text.strip()
                                logger.info(f"‚úÖ –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç ({len(title)} —Å–∏–º–≤–æ–ª–æ–≤): {title[:200]}...")
                                
                                if len(title) > 30:  # –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–µ–∫—Å—Ç–∞
                                    break
                            else:
                                # –°—Ç–∞—Ä–∞—è –ª–æ–≥–∏–∫–∞ –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤
                                lines = all_text.split('\n')
                                valid_lines = []
                                
                                for line in lines:
                                    line = line.strip()
                                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç—Ä–æ–∫–∏ —Å —Ç–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä–∞–º–∏, –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–µ —Å—Ç—Ä–æ–∫–∏, —Å–ª—É–∂–µ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
                                    if (line and len(line) > 5 and  # –ú–∏–Ω–∏–º—É–º 5 —Å–∏–º–≤–æ–ª–æ–≤
                                        not line.isdigit() and  # –ù–µ —á–∏—Å–ª–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
                                        not line.startswith('@') and  # –ù–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è
                                        'ago' not in line.lower() and
                                        'reply' not in line.lower() and
                                        'retweet' not in line.lower() and
                                        'show this thread' not in line.lower()):
                                        valid_lines.append(line)
                                
                                if valid_lines:
                                    title = ' '.join(valid_lines)
                                    if len(title) > 10:  # –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–µ–∫—Å—Ç–∞
                                        break
                    except Exception as e:
                        logger.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞ —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–º {selector}: {e}")
                        continue
                
                # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —á–µ—Ä–µ–∑ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã, –∏—â–µ–º –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ
                if not title:
                    # –ò—â–µ–º –≤ article —Å lang –∞—Ç—Ä–∏–±—É—Ç–æ–º
                    articles = soup.find_all('article')
                    for article in articles:
                        lang_elem = article.find(attrs={'lang': True})
                        if lang_elem:
                            title = lang_elem.get_text().strip()
                            break
                
                # –ï—Å–ª–∏ –≤—Å–µ –µ—â–µ –Ω–µ –Ω–∞—à–ª–∏, –∏—â–µ–º –ª—é–±–æ–π —Ç–µ–∫—Å—Ç –≤ —Ç–≤–∏—Ç–µ
                if not title:
                    # –ò—â–µ–º div —Å data-testid="tweet"
                    tweet_divs = soup.find_all('div', {'data-testid': 'tweet'})
                    for tweet_div in tweet_divs:
                        # –ò—â–µ–º —Ç–µ–∫—Å—Ç –≤ –¥–æ—á–µ—Ä–Ω–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–∞—Ö
                        text_elements = tweet_div.find_all(['div', 'span', 'p'], string=True)
                        for elem in text_elements:
                            text = elem.get_text().strip()
                            if len(text) > 10 and not any(skip in text.lower() for skip in ['follow', 'retweet', 'like', 'reply', 'share']):
                                title = text
                                break
                        if title:
                            break
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ (—Ç–æ –∂–µ —á—Ç–æ –∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–ª—è —Ç–≤–∏—Ç–æ–≤)
                description = title
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞—Ç—É –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
                published = ""
                date_selectors = [
                    'time[datetime]',
                    '[data-testid="tweet"] time',
                    'article time'
                ]
                
                for selector in date_selectors:
                    date_elem = soup.select_one(selector)
                    if date_elem:
                        published = date_elem.get('datetime', '').strip()
                        break
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∞–≤—Ç–æ—Ä–∞ –¥–ª—è –∞–≤–∞—Ç–∞—Ä–∫–∏, –Ω–æ –Ω–µ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
                author = "Twitter User"  # –ë–∞–∑–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                username = ""  # –î–ª—è –∞–≤–∞—Ç–∞—Ä–∫–∏
                try:
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∞–≤—Ç–æ—Ä–∞ –∏–∑ URL
                    import re
                    username_match = re.search(r'(?:twitter\.com|x\.com)/([^/]+)', url)
                    if username_match:
                        author = username_match.group(1)
                        username = author  # –°–æ—Ö—Ä–∞–Ω—è–µ–º username –¥–ª—è –∞–≤–∞—Ç–∞—Ä–∫–∏
                        logger.info(f"üê¶ –ò–∑–≤–ª–µ—á–µ–Ω username: @{username}")
                    else:
                        logger.warning(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å username –∏–∑ URL: {url}")
                except Exception as e:
                    logger.warning(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è username: {e}")

                # –ò–∑–≤–ª–µ–∫–∞–µ–º URL –∞–≤–∞—Ç–∞—Ä–∞
                avatar_url = ""
                try:
                    # –ò—â–µ–º –∞–≤–∞—Ç–∞—Ä –ø–æ —Å–µ–ª–µ–∫—Ç–æ—Ä—É, –∫–æ—Ç–æ—Ä—ã–π —á–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –∞–≤–∞—Ç–∞—Ä–æ–∫ –≤ —Ç–≤–∏—Ç–∞—Ö
                    avatar_selectors = [
                        'div[data-testid="tweet"] a[role="link"] img',
                        'article[data-testid="tweet"] div[data-testid^="UserAvatar-Container"] img',
                        'div[data-testid="tweet"] img[alt$="profile image"]'
                    ]
                    for selector in avatar_selectors:
                        avatar_img = soup.select_one(selector)
                        if avatar_img and 'profile_images' in avatar_img.get('src', ''):
                            avatar_url = avatar_img['src'].replace('_normal', '_400x400')
                            logger.info(f"üñºÔ∏è –ù–∞–π–¥–µ–Ω URL –∞–≤–∞—Ç–∞—Ä–∞: {avatar_url}")
                            break
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å URL –∞–≤–∞—Ç–∞—Ä–∞: {e}")
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Ç–≤–∏—Ç–∞ - LLM —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –±—Ä–æ—Å–∫–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
                short_title = title
                
                # –ö–æ–Ω—Ç–µ–Ω—Ç = –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —Ç–≤–∏—Ç–∞
                content_text = title
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ–¥–∏–∞ —Ñ–∞–π–ª—ã (–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, GIF, –≤–∏–¥–µ–æ) - –∫–∞–∫ –≤ —Å—Ç–∞—Ä–æ–º –∫–æ–¥–µ
                images = []
                videos = []
                try:
                    # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ GIF
                    image_selectors = [
                        '[data-testid="tweetPhoto"] img',
                        'article[data-testid="tweet"] img[alt="Image"]',
                        'div[data-testid="card.wrapper"] img',
                        'article img[src*="media"]'
                    ]
                    for selector in image_selectors:
                        img_elements = driver.find_elements(By.CSS_SELECTOR, selector)
                        for img in img_elements:
                            src = img.get_attribute('src')
                            if src and src not in images:
                                # Clean up the URL
                                if 'pbs.twimg.com' in src:
                                    if 'format=gif' in src:
                                        src = src.replace('format=gif', 'format=jpg')
                                    if 'name=medium' in src:
                                        src = src.replace('name=medium', 'name=large')
                                    elif 'name=small' in src:
                                        src = src.replace('name=small', 'name=large')
                                
                                if src not in images:
                                    images.append(src)
                            if len(images) >= 3:
                                break
                        if len(images) >= 3:
                            break
                    
                    # –í–∏–¥–µ–æ - —É–ª—É—á—à–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫
                    video_selectors = [
                        '[data-testid="videoPlayer"] video',
                        '[data-testid="videoComponent"] video',
                        'video[poster*="amplify_video"]',
                        'video[src*=".mp4"]',
                        '[role="button"] video'
                    ]
                    
                    for selector in video_selectors:
                        video_elements = driver.find_elements(By.CSS_SELECTOR, selector)
                        for video in video_elements[:3-len(images)]:
                            # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É –Ω–∞ –≤–∏–¥–µ–æ
                            src = video.get_attribute('src')
                            poster = video.get_attribute('poster')
                            
                            if src and '.mp4' in src and src not in videos:
                                videos.append(src)
                                logger.info(f"üé¨ –ù–∞–π–¥–µ–Ω–æ –≤–∏–¥–µ–æ: {src[:50]}...")
                            elif poster and poster not in images:
                                # –ï—Å–ª–∏ –µ—Å—Ç—å poster, –ø—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å –≤–∏–¥–µ–æ –∏–∑ –Ω–µ–≥–æ
                                if 'amplify_video_thumb' in poster:
                                    # –ü—Ä–æ–±—É–µ–º –∑–∞–º–µ–Ω–∏—Ç—å thumb –Ω–∞ –≤–∏–¥–µ–æ
                                    video_url = poster.replace('amplify_video_thumb', 'amplify_video').replace('/img/', '/vid/').replace('.jpg', '.mp4')
                                    if video_url not in videos:
                                        videos.append(video_url)
                                        logger.info(f"üé¨ –ù–∞–π–¥–µ–Ω–æ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ –≤–∏–¥–µ–æ: {video_url[:50]}...")
                                if poster not in images:
                                    images.append(poster)
                        
                        if len(videos) >= 3:
                            break
                    
                    # –ü–æ–∏—Å–∫ –≤–∏–¥–µ–æ —á–µ—Ä–µ–∑ meta —Ç–µ–≥–∏
                    try:
                        meta_video_selectors = [
                            'meta[property="og:video"]',
                            'meta[property="og:video:url"]',
                            'meta[property="twitter:player:stream"]',
                            'meta[name="twitter:player:stream"]'
                        ]
                        
                        for selector in meta_video_selectors:
                            meta_elements = driver.find_elements(By.CSS_SELECTOR, selector)
                            for meta in meta_elements:
                                content = meta.get_attribute('content')
                                if content and content not in videos and ('.mp4' in content or 'video' in content):
                                    videos.append(content)
                                    logger.info(f"üé¨ –ù–∞–π–¥–µ–Ω–æ –≤–∏–¥–µ–æ —á–µ—Ä–µ–∑ meta: {content[:50]}...")
                                    break
                    except Exception as e:
                        logger.debug(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤–∏–¥–µ–æ —á–µ—Ä–µ–∑ meta: {e}")
                    
                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ GIF –≤ Twitter
                    gif_elements = driver.find_elements(By.CSS_SELECTOR, 'video[poster*="gif"], img[src*="gif"]')
                    for gif in gif_elements[:3-len(images)]:
                        src = gif.get_attribute('src') or gif.get_attribute('poster')
                        if src and src not in images:
                            images.append(src)
                            
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –º–µ–¥–∏–∞ –∏–∑ Twitter: {e}")
                    pass
                
                # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
                images = list(dict.fromkeys(images))
                videos = list(dict.fromkeys(videos))
                
                logger.info(f"üìù Twitter –ø–∞—Ä—Å–∏–Ω–≥: –∑–∞–≥–æ–ª–æ–≤–æ–∫='{short_title[:50]}...', –∫–æ–Ω—Ç–µ–Ω—Ç={len(content_text)} —Å–∏–º–≤–æ–ª–æ–≤, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è={len(images)}, –≤–∏–¥–µ–æ={len(videos)}")
                
                return {
                    'title': short_title,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ—Ä–æ—Ç–∫–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
                    'description': description,
                    'content': content_text,
                    'published': published,
                    'images': images,
                    'videos': videos,
                    'username': username,  # –î–æ–±–∞–≤–ª—è–µ–º username –¥–ª—è –∞–≤–∞—Ç–∞—Ä–∫–∏
                    'avatar_url': avatar_url, # –î–æ–±–∞–≤–ª—è–µ–º URL –∞–≤–∞—Ç–∞—Ä–∞
                    'source': 'TWITTER',
                    'content_type': 'social_media_post'
                }
                
            finally:
                driver.quit()
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ Selenium –ø–∞—Ä—Å–∏–Ω–≥–∞ Twitter: {e}")
            import traceback
            logger.error(f"‚ùå Traceback: {traceback.format_exc()}")
            return {}
    
    def _is_blocked_content(self, content: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω –ª–∏ –∫–æ–Ω—Ç–µ–Ω—Ç"""
        if not content:
            return False
        
        blocked_indicators = [
            'something went wrong',
            'try again',
            'privacy related extensions',
            'disable them and try again',
            'this page is not available',
            'tweet unavailable',
            'tweet not found',
            'don\'t fret',
            'give it another shot'
        ]
        
        content_lower = content.lower()
        for indicator in blocked_indicators:
            if indicator in content_lower:
                return True
        
        return False
    
    def _get_fallback_content(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç fallback –∫–æ–Ω—Ç–µ–Ω—Ç"""
        return {
            'title': 'Twitter Post',
            'description': 'Twitter post content unavailable',
            'content': 'Content could not be parsed from Twitter',
            'images': [],
            'videos': [],
            'published': '',
            'source': 'TWITTER',
            'content_type': 'social_media_post'
        }
    
    def _get_supported_domains(self) -> List[str]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –¥–æ–º–µ–Ω—ã"""
        return ['x.com', 'www.x.com', 'twitter.com', 'www.twitter.com']
