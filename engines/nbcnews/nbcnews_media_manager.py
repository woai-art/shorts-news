#!/usr/bin/env python3
"""
NBC News Media Manager
–û–±—Ä–∞–±–æ—Ç–∫–∞ –º–µ–¥–∏–∞ –¥–ª—è NBC News
"""

import logging
import os
import requests
from pathlib import Path
from typing import Dict, List, Any, Optional

logger = logging.getLogger(__name__)

class NBCNewsMediaManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –º–µ–¥–∏–∞ –¥–ª—è NBC News"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.media_dir = Path('resources') / 'media' / 'news'
        self.media_dir.mkdir(parents=True, exist_ok=True)
        
        # –î–æ–º–µ–Ω—ã NBC News –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        self.allowed_domains = [
            'nbcnews.com',
            'media.nbcnews.com',
            'media1.nbcnews.com',
            'media2.nbcnews.com',
            'media3.nbcnews.com',
            'media4.nbcnews.com',
            'media5.nbcnews.com'
        ]
    
    def process_news_media(self, news_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –º–µ–¥–∏–∞ –¥–ª—è –Ω–æ–≤–æ—Å—Ç–∏ NBC News
        
        Args:
            news_data: –î–∞–Ω–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –º–µ–¥–∏–∞
        """
        try:
            logger.info(f"üì∫ –û–±—Ä–∞–±–æ—Ç–∫–∞ NBC News –º–µ–¥–∏–∞...")
            
            images = news_data.get('images', [])
            videos = news_data.get('videos', [])
            
            logger.info(f"üì∏ –ù–∞–π–¥–µ–Ω–æ {len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, {len(videos)} –≤–∏–¥–µ–æ")
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            filtered_images = self._filter_images(images)
            logger.info(f"‚úÖ –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ {len(filtered_images)} NBC News –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
            for i, img_url in enumerate(filtered_images):
                logger.info(f"  üì∏ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {i+1}: {img_url}")
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º –≤–∏–¥–µ–æ
            filtered_videos = self._filter_videos(videos)
            logger.info(f"‚úÖ –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ {len(filtered_videos)} NBC News –≤–∏–¥–µ–æ")
            for i, video_url in enumerate(filtered_videos):
                logger.info(f"  üé¨ –í–∏–¥–µ–æ {i+1}: {video_url}")
            
            # –°–∫–∞—á–∏–≤–∞–µ–º –ø–µ—Ä–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            local_image_path = None
            if filtered_images:
                for img_url in filtered_images:
                    local_image_path = self._download_image(img_url, news_data.get('title', 'nbc_news'))
                    if local_image_path:
                        break  # –ï—Å–ª–∏ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å, –ø—Ä–µ–∫—Ä–∞—â–∞–µ–º –ø–æ–ø—ã—Ç–∫–∏
            
            # –°–∫–∞—á–∏–≤–∞–µ–º –ø–µ—Ä–≤–æ–µ –≤–∏–¥–µ–æ
            local_video_path = None
            if filtered_videos:
                for video_url in filtered_videos:
                    local_video_path = self._download_video(video_url, news_data.get('title', 'nbc_news'))
                    if local_video_path:
                        break  # –ï—Å–ª–∏ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å, –ø—Ä–µ–∫—Ä–∞—â–∞–µ–º –ø–æ–ø—ã—Ç–∫–∏
            
            has_media = bool(local_image_path or local_video_path)
            
            result = {
                'local_image_path': local_image_path,
                'local_video_path': local_video_path,
                'processed_images': [local_image_path] if local_image_path else [],
                'processed_videos': [local_video_path] if local_video_path else [],
                'has_media': has_media
            }
            
            logger.info(f"üì∫ NBC News –º–µ–¥–∏–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: has_media={has_media}")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ NBC News –º–µ–¥–∏–∞: {e}")
            return {
                'local_image_path': None,
                'local_video_path': None,
                'processed_images': [],
                'processed_videos': [],
                'has_media': False
            }
    
    def _filter_images(self, images: List[str]) -> List[str]:
        """–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π NBC News"""
        filtered = []
        
        for img_url in images:
            if self._is_nbc_image(img_url):
                filtered.append(img_url)
        
        return filtered
    
    def _filter_videos(self, videos: List[str]) -> List[str]:
        """–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ NBC News"""
        filtered = []
        
        for video_url in videos:
            if self._is_nbc_video(video_url):
                filtered.append(video_url)
        
        return filtered
    
    def _is_nbc_image(self, url: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º NBC News"""
        if not url:
            return False
        
        # –ò—Å–∫–ª—é—á–∞–µ–º blob URLs –∏ –Ω–µ–ø–æ–ª–Ω—ã–µ URL
        if url.startswith('blob:') or url.startswith('data:'):
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ–º–µ–Ω—ã NBC News
        for domain in self.allowed_domains:
            if domain in url:
                return True
        
        return False
    
    def _is_nbc_video(self, url: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ URL –≤–∏–¥–µ–æ NBC News"""
        if not url:
            return False
        
        # –ò—Å–∫–ª—é—á–∞–µ–º blob URLs –∏ –Ω–µ–ø–æ–ª–Ω—ã–µ URL
        if url.startswith('blob:') or url.startswith('data:'):
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ–º–µ–Ω—ã NBC News
        for domain in self.allowed_domains:
            if domain in url:
                return True
        
        return False
    
    def _download_image(self, image_url: str, title: str) -> Optional[str]:
        """–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ URL –≤–∞–ª–∏–¥–Ω—ã–π
            if not image_url or image_url.startswith('blob:') or image_url.startswith('data:'):
                logger.warning(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {image_url}")
                return None
            
            # –°–æ–∑–¥–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
            safe_title = "".join(c for c in title if c.isalnum() or c in (' ', '-', '_')).rstrip()
            safe_title = safe_title[:50]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
            
            filename = f"nbc_{safe_title}_{hash(image_url) % 1000000}.jpg"
            file_path = self.media_dir / filename
            
            # –î–æ–±–∞–≤–ª—è–µ–º User-Agent –¥–ª—è –æ–±—Ö–æ–¥–∞ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            }
            
            # –°–∫–∞—á–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            response = requests.get(image_url, timeout=30, headers=headers)
            response.raise_for_status()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            content_type = response.headers.get('content-type', '')
            if not content_type.startswith('image/'):
                logger.warning(f"‚ö†Ô∏è URL –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º: {content_type}")
                return None
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
            with open(file_path, 'wb') as f:
                f.write(response.content)
            
            logger.info(f"‚úÖ NBC News –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–∫–∞—á–∞–Ω–æ: {file_path}")
            return str(file_path)
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {image_url}: {e}")
            return None
    
    def _download_video(self, video_url: str, title: str) -> Optional[str]:
        """–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –≤–∏–¥–µ–æ"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ URL –≤–∞–ª–∏–¥–Ω—ã–π
            if not video_url or video_url.startswith('blob:') or video_url.startswith('data:'):
                logger.warning(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π URL –≤–∏–¥–µ–æ: {video_url}")
                return None
            
            # –°–æ–∑–¥–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
            safe_title = "".join(c for c in title if c.isalnum() or c in (' ', '-', '_')).rstrip()
            safe_title = safe_title[:50]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
            
            filename = f"nbc_{safe_title}_{hash(video_url) % 1000000}.mp4"
            file_path = self.media_dir / filename
            
            # –î–æ–±–∞–≤–ª—è–µ–º User-Agent –¥–ª—è –æ–±—Ö–æ–¥–∞ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            }
            
            # –°–∫–∞—á–∏–≤–∞–µ–º –≤–∏–¥–µ–æ
            response = requests.get(video_url, timeout=60, headers=headers)
            response.raise_for_status()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –≤–∏–¥–µ–æ
            content_type = response.headers.get('content-type', '')
            if not content_type.startswith('video/'):
                logger.warning(f"‚ö†Ô∏è URL –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –≤–∏–¥–µ–æ: {content_type}")
                return None
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
            with open(file_path, 'wb') as f:
                f.write(response.content)
            
            logger.info(f"‚úÖ NBC News –≤–∏–¥–µ–æ —Å–∫–∞—á–∞–Ω–æ: {file_path}")
            return str(file_path)
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å –≤–∏–¥–µ–æ {video_url}: {e}")
            return None
