#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –ø–æ–∏—Å–∫–∞ AP News –≤–∏–¥–µ–æ —á–µ—Ä–µ–∑ DuckDuckGo
"""

import requests
from bs4 import BeautifulSoup
import re

def search_apnews_video():
    """–ò—â–µ–º AP News –≤–∏–¥–µ–æ —á–µ—Ä–µ–∑ DuckDuckGo"""
    
    print("üîç –ü–æ–∏—Å–∫ AP News –≤–∏–¥–µ–æ —á–µ—Ä–µ–∑ DuckDuckGo:")
    print("=" * 60)
    
    # –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
    query = "site:apnews.com Trump Epstein Windsor Castle video"
    search_url = f"https://duckduckgo.com/html/?q={query}"
    
    print(f"Query: {query}")
    print(f"URL: {search_url}")
    print("=" * 60)
    
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        response = requests.get(search_url, headers=headers, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # –ò—â–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ AP News
        links = soup.find_all('a', href=True)
        ap_links = []
        
        for link in links:
            href = link.get('href', '')
            if 'apnews.com' in href and 'video' in href:
                ap_links.append(href)
        
        print(f"–ù–∞–π–¥–µ–Ω–æ {len(ap_links)} —Å—Å—ã–ª–æ–∫ –Ω–∞ AP News –≤–∏–¥–µ–æ:")
        for i, link in enumerate(ap_links[:5], 1):
            print(f"{i}. {link}")
        
        if ap_links:
            # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø–µ—Ä–≤—É—é —Å—Å—ã–ª–∫—É
            test_url = ap_links[0]
            print(f"\nüîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º: {test_url}")
            
            response = requests.get(test_url, headers=headers, timeout=10)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # –ò—â–µ–º –≤–∏–¥–µ–æ
            print("\nüé• –ü–æ–∏—Å–∫ –≤–∏–¥–µ–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤:")
            
            # HTML5 video
            video_tags = soup.find_all('video')
            print(f"HTML5 video —Ç–µ–≥–∏: {len(video_tags)}")
            for video in video_tags:
                src = video.get('src')
                if src:
                    print(f"  - src: {src}")
            
            # iframe
            iframes = soup.find_all('iframe')
            print(f"iframe —Ç–µ–≥–∏: {len(iframes)}")
            for iframe in iframes:
                src = iframe.get('src')
                if src:
                    print(f"  - src: {src}")
            
            # data-–∞—Ç—Ä–∏–±—É—Ç—ã
            data_video = soup.find_all(attrs={'data-video-url': True})
            print(f"data-video-url –∞—Ç—Ä–∏–±—É—Ç—ã: {len(data_video)}")
            for elem in data_video:
                video_url = elem.get('data-video-url')
                print(f"  - data-video-url: {video_url}")
            
            # –ò—â–µ–º –≤ —Ç–µ–∫—Å—Ç–µ
            text = soup.get_text()
            video_patterns = [
                r'https://[^\s]+\.mp4',
                r'https://[^\s]+\.webm',
                r'https://[^\s]+\.mov',
                r'data-video-url="([^"]+)"',
                r'"videoUrl":"([^"]+)"',
                r'"video_url":"([^"]+)"'
            ]
            
            print("\nüîç –ü–æ–∏—Å–∫ –≤–∏–¥–µ–æ URL –≤ —Ç–µ–∫—Å—Ç–µ:")
            for pattern in video_patterns:
                matches = re.findall(pattern, text, re.IGNORECASE)
                if matches:
                    print(f"  {pattern}: {matches}")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 1000 —Å–∏–º–≤–æ–ª–æ–≤ HTML
            print(f"\nüìÑ –ü–µ—Ä–≤—ã–µ 1000 —Å–∏–º–≤–æ–ª–æ–≤ HTML:")
            print(response.text[:1000])
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")

if __name__ == "__main__":
    search_apnews_video()
