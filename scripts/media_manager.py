#!/usr/bin/env python3
"""
–ú–µ–Ω–µ–¥–∂–µ—Ä –º–µ–¥–∏–∞-—Ñ–∞–π–ª–æ–≤ –¥–ª—è shorts_news
–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –≤–∏–¥–µ–æ –∏–∑ –Ω–æ–≤–æ—Å—Ç–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π
"""

import os
import logging
import hashlib
import requests
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from PIL import Image, ImageOps, ImageEnhance
import uuid
import base64
import io
from urllib.parse import urlparse, urljoin

logger = logging.getLogger(__name__)

class MediaManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–µ–¥–∏–∞-—Ñ–∞–π–ª–∞–º–∏"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.media_dir = Path("resources/media/news")
        self.media_dir.mkdir(parents=True, exist_ok=True)
        self.selenium_driver = None  # –î–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ WebDriver –∏–∑ WebParser
        
        # –°–ø–∏—Å–æ–∫ User-Agent –¥–ª—è —Ä–æ—Ç–∞—Ü–∏–∏ (–∫–∞–∫ –≤ WebParser)
        self.user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Safari/605.1.15'
        ]
        
        # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã
        self.supported_image_formats = {'.jpg', '.jpeg', '.png', '.webp'}
        self.supported_gif_formats = {'.gif'}
        self.supported_video_formats = {'.mp4', '.avi', '.mov', '.webm', '.mkv'}
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –º–µ–¥–∏–∞ –æ–±–ª–∞—Å—Ç–∏ (16:9 —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ)
        self.target_size = (960, 540)  # –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è –º–µ–¥–∏–∞-–∑–æ–Ω—ã
        
        # –ß–∏—Ç–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Å fallback –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
        news_parser_config = config.get('news_parser', {})
        self.max_file_size = news_parser_config.get('max_image_size_mb', 10) * 1024 * 1024
        self.max_video_size = news_parser_config.get('max_video_size_mb', 100) * 1024 * 1024
        self.max_video_duration = news_parser_config.get('max_video_duration_seconds', 300)
        self.target_short_duration = news_parser_config.get('target_short_duration_seconds', 15)
        
        # –õ–æ–≥–∏—Ä—É–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–µ–¥–∏–∞
        logger.info(f"üìπ –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–µ–¥–∏–∞: –º–∞–∫—Å. –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤–∏–¥–µ–æ {self.max_video_duration}—Å, –º–∞–∫—Å. —Ä–∞–∑–º–µ—Ä –≤–∏–¥–µ–æ {self.max_video_size//1024//1024}MB")
    
    def set_selenium_driver(self, driver):
        """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç WebDriver –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –∑–∞–≥—Ä—É–∑–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
        self.selenium_driver = driver
        
    def process_news_media(self, news_data: Dict) -> Dict[str, str]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –º–µ–¥–∏–∞-–¥–∞–Ω–Ω—ã—Ö –¥–ª—è –Ω–æ–≤–æ—Å—Ç–∏"""
        media_result = {
            'primary_image': None,
            'video_url': None,
            'thumbnail': None,
            'local_image_path': None,
            'local_video_path': None
        }
        
        try:
            images = news_data.get('images', [])
            
            if images:
                logger.info(f"üì∏ –ù–∞–π–¥–µ–Ω–æ {len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
                
                # –î–ª—è Twitter –ø–æ—Å—Ç–æ–≤ —Å–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –≤–∏–¥–µ–æ, –ø–æ—Ç–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                is_twitter = news_data.get('source', '').lower() in ['twitter', 'twitter/x']
                if is_twitter:
                    logger.info("üê¶ –û–±–Ω–∞—Ä—É–∂–µ–Ω Twitter –ø–æ—Å—Ç - –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –≤–∏–¥–µ–æ –Ω–∞–¥ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏")
                    
                    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º —Å–∫–∞—á–∞—Ç—å –≤–∏–¥–µ–æ —á–µ—Ä–µ–∑ yt-dlp –¥–ª—è –≤—Å–µ–≥–æ —Ç–≤–∏—Ç–∞
                    tweet_url = news_data.get('url', '')
                    if tweet_url and ('twitter.com' in tweet_url or 'x.com' in tweet_url):
                        logger.info(f"üé¨ –ü—Ä–æ–±—É–µ–º —Å–∫–∞—á–∞—Ç—å –≤–∏–¥–µ–æ –∏–∑ —Ç–≤–∏—Ç–∞: {tweet_url}")
                        video_path = self._download_and_process_video(
                            tweet_url,
                            news_data.get('title', 'twitter_video')
                        )
                        if video_path:
                            media_result.update({
                                'video_url': tweet_url,
                                'local_video_path': video_path,
                                'thumbnail': video_path
                            })
                            logger.info(f"‚úÖ Twitter –≤–∏–¥–µ–æ —É—Å–ø–µ—à–Ω–æ —Å–∫–∞—á–∞–Ω–æ: {video_path}")
                            return media_result
                
                for media_item in images:
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º URL –∏–∑ —Å–ª–æ–≤–∞—Ä—è –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞–∫ —Å—Ç—Ä–æ–∫—É
                    if isinstance(media_item, dict):
                        media_url = media_item.get('url', media_item.get('src', ''))
                    else:
                        media_url = media_item
                    
                    if not media_url:
                        logger.warning("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω URL –≤ —ç–ª–µ–º–µ–Ω—Ç–µ –º–µ–¥–∏–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º.")
                        continue

                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –º–µ–¥–∏–∞
                    media_type = self._detect_media_type(media_url)
                    logger.info(f"üîç –û–±–Ω–∞—Ä—É–∂–µ–Ω —Ç–∏–ø –º–µ–¥–∏–∞: {media_type} –¥–ª—è {media_url[:50]}...")
                    
                    local_path = None
                    
                    if media_type == 'gif':
                        local_path = self._download_and_process_gif(
                            media_url,
                            news_data.get('title', 'news')
                        )
                        if local_path:
                            media_result.update({
                                'primary_image': media_url,
                                'local_image_path': local_path,
                                'thumbnail': local_path
                            })
                            logger.info(f"‚úÖ GIF —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω: {local_path}")
                            break
                    
                    elif media_type == 'video':
                        local_path = self._download_and_process_video(
                            media_url,
                            news_data.get('title', 'news')
                        )
                        if local_path:
                            media_result.update({
                                'video_url': media_url,
                                'local_video_path': local_path,
                                'thumbnail': local_path  # –í–∏–¥–µ–æ –º–æ–∂–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –∫–∞–∫ thumbnail
                            })
                            logger.info(f"‚úÖ –í–∏–¥–µ–æ —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {local_path}")
                            break
                    
                    else:  # –û–±—ã—á–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                        local_path = self._download_and_process_image(
                            media_url,
                            news_data.get('title', 'news')
                        )
                        if local_path:
                            media_result.update({
                                'primary_image': media_url,
                                'local_image_path': local_path,
                                'thumbnail': local_path
                            })
                            logger.info(f"‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {local_path}")
                            break
                    
                    if not local_path:
                        logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –º–µ–¥–∏–∞: {media_url}, –ø—Ä–æ–±—É–µ–º —Å–ª–µ–¥—É—é—â–µ–µ.")
                
                if not media_result.get('local_image_path') and not media_result.get('local_video_path'):
                     logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ –º–µ–¥–∏–∞ —Ñ–∞–π–ª–∞ –∏–∑ —Å–ø–∏—Å–∫–∞.")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤–∏–¥–µ–æ (–µ—Å–ª–∏ –±—É–¥–µ—Ç –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –≤ –±—É–¥—É—â–µ–º)
            video_url = news_data.get('video_url')
            if video_url:
                logger.info(f"üé¨ –ù–∞–π–¥–µ–Ω–æ –≤–∏–¥–µ–æ: {video_url}")
                media_result['video_url'] = video_url
            
            return media_result
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –º–µ–¥–∏–∞: {e}")
            return media_result
    
    def _is_animated_gif(self, file_path: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ GIF —Ñ–∞–π–ª –∞–Ω–∏–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–º"""
        try:
            from PIL import Image
            with Image.open(file_path) as img:
                # –ï—Å–ª–∏ GIF –∏–º–µ–µ—Ç –±–æ–ª–µ–µ –æ–¥–Ω–æ–≥–æ –∫–∞–¥—Ä–∞, –æ–Ω –∞–Ω–∏–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–π
                img.seek(1)  # –ü—ã—Ç–∞–µ–º—Å—è –ø–µ—Ä–µ–π—Ç–∏ –∫–æ –≤—Ç–æ—Ä–æ–º—É –∫–∞–¥—Ä—É
                return True
        except (EOFError, OSError):
            # –ï—Å–ª–∏ –Ω–µ –º–æ–∂–µ–º –ø–µ—Ä–µ–π—Ç–∏ –∫–æ –≤—Ç–æ—Ä–æ–º—É –∫–∞–¥—Ä—É, GIF —Å—Ç–∞—Ç–∏—á–Ω—ã–π
            return False
        except Exception:
            return False

    def _detect_media_type(self, url: str, headers: Dict = None) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –º–µ–¥–∏–∞ —Ñ–∞–π–ª–∞ –ø–æ URL –∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º"""
        from urllib.parse import urlparse
        
        url_lower = url.lower()
        
        # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞ –¥–ª—è Twitter –º–µ–¥–∏–∞
        if 'pbs.twimg.com' in url_lower:
            if 'amplify_video' in url_lower:
                return 'video'
            elif 'tweet_video' in url_lower:
                return 'video'
            elif '.mp4' in url_lower:
                return 'video'
            elif 'format=gif' in url_lower:
                # Twitter –º–æ–∂–µ—Ç —É–∫–∞–∑–∞—Ç—å format=gif –¥–ª—è —Å—Ç–∞—Ç–∏—á–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∞–ª—å–Ω—ã–π —Ç–∏–ø –ø–æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
                return 'image'  # –ë—É–¥–µ–º –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –∫–∞–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            elif '.gif' in url_lower:
                return 'gif'
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ –≤ URL
        parsed_url = urlparse(url_lower)
        path = parsed_url.path
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
        if '.' in path:
            ext = '.' + path.split('.')[-1]
            if ext in self.supported_video_formats:
                return 'video'
            elif ext in self.supported_gif_formats:
                return 'gif'
            elif ext in self.supported_image_formats:
                return 'image'
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º Content-Type –≤ –∑–∞–≥–æ–ª–æ–≤–∫–∞—Ö
        if headers:
            content_type = headers.get('content-type', '').lower()
            if content_type.startswith('video/'):
                return 'video'
            elif content_type.startswith('image/gif'):
                return 'gif'
            elif content_type.startswith('image/'):
                return 'image'
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º –≤ URL
        if any(keyword in url_lower for keyword in ['video', 'mp4', 'webm', 'mov']):
            return 'video'
        elif any(keyword in url_lower for keyword in ['gif']):
            return 'gif'
        
        # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å—á–∏—Ç–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º
        return 'image'
    
    def _download_and_process_image(self, image_url: str, news_title: str) -> Optional[str]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        try:
            # –§–∏–ª—å—Ç—Ä—É–µ–º –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ URL
            if image_url.startswith(('data:', 'javascript:', '#', 'blob:')):
                logger.warning(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π URL: {image_url[:50]}...")
                return None
            # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
            url_hash = hashlib.md5(image_url.encode()).hexdigest()[:8]
            safe_title = "".join(c for c in news_title[:20] if c.isalnum() or c in (' ', '-', '_')).strip()
            safe_title = safe_title.replace(' ', '_')
            
            filename = f"{safe_title}_{url_hash}.jpg"
            local_path = self.media_dir / filename
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –ª–∏ —É–∂–µ
            if local_path.exists():
                logger.info(f"üìÅ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {local_path}")
                return str(local_path)
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å retry –º–µ—Ö–∞–Ω–∏–∑–º–æ–º
            logger.info(f"‚¨áÔ∏è –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_url}")
            
            # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è POLITICO –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            if 'politico.com' in image_url:
                image_data = self._download_politico_image(image_url)
                if image_data:
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞–ø—Ä—è–º—É—é
                    temp_path = local_path.with_suffix('.tmp')
                    with open(temp_path, 'wb') as f:
                        f.write(image_data)
                    temp_path.rename(local_path)
                    logger.info(f"‚úÖ POLITICO –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {local_path}")
                    return str(local_path)
            
            # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è Le Monde –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            if 'lemonde.fr' in image_url or 'img.lemde.fr' in image_url:
                image_data = self._download_lemonde_image(image_url)
                if image_data:
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞–ø—Ä—è–º—É—é
                    temp_path = local_path.with_suffix('.tmp')
                    with open(temp_path, 'wb') as f:
                        f.write(image_data)
                    temp_path.rename(local_path)
                    logger.info(f"‚úÖ Le Monde –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {local_path}")
                    return str(local_path)
            
            response = self._download_with_retry(image_url)
            if not response:
                # –ü—Ä–æ–±—É–µ–º Selenium fallback –¥–ª—è –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
                logger.info(f"üîÑ –ü—Ä–æ–±—É–µ–º Selenium fallback –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {image_url}")
                image_data = self._download_with_selenium(image_url, self.selenium_driver)
                if image_data:
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞–ø—Ä—è–º—É—é
                    temp_path = local_path.with_suffix('.tmp')
                    with open(temp_path, 'wb') as f:
                        f.write(image_data)
                    response = None  # –£–∫–∞–∑—ã–≤–∞–µ–º, —á—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä—è–º—ã–µ –¥–∞–Ω–Ω—ã–µ
                else:
                    logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–∞–∂–µ —á–µ—Ä–µ–∑ Selenium: {image_url}")
                    return None
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
            temp_path = local_path.with_suffix('.tmp')
            
            if response:  # –û–±—ã—á–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —á–µ—Ä–µ–∑ requests
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
                content_length = response.headers.get('Content-Length')
                if content_length and int(content_length) > self.max_file_size:
                    logger.warning(f"‚ö†Ô∏è –§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π: {content_length} –±–∞–π—Ç")
                    return None
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ
                with open(temp_path, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        f.write(chunk)
            # else: —Ñ–∞–π–ª —É–∂–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω —á–µ—Ä–µ–∑ Selenium –≤—ã—à–µ
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            processed_path = self._process_image_for_shorts(temp_path, local_path)
            
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            temp_path.unlink()
            
            return processed_path
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {image_url}: {e}")
            return None
    
    def _process_image_for_shorts(self, input_path: Path, output_path: Path) -> Optional[str]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: –∏–∑–º–µ–Ω—è–µ—Ç —Ä–∞–∑–º–µ—Ä —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø—Ä–æ–ø–æ—Ä—Ü–∏–π –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç –ø–æ–ª—è (letterbox)."""
        try:
            with Image.open(input_path) as img:
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ RGB, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                if img.mode != 'RGB':
                    img = img.convert('RGB')

                # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é, —á—Ç–æ–±—ã .thumbnail –Ω–µ –∏–∑–º–µ–Ω–∏–ª –æ—Ä–∏–≥–∏–Ω–∞–ª
                img_copy = img.copy()
                
                # thumbnail –∏–∑–º–µ–Ω—è–µ—Ç —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è inplace, —Å–æ—Ö—Ä–∞–Ω—è—è –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏, —á—Ç–æ–±—ã –æ–Ω–æ –≤–ª–µ–∑–ª–æ –≤ target_size
                img_copy.thumbnail(self.target_size, Image.Resampling.LANCZOS)

                # –°–æ–∑–¥–∞–µ–º —á–µ—Ä–Ω—ã–π —Ñ–æ–Ω –Ω—É–∂–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ (960x540)
                background = Image.new('RGB', self.target_size, (0, 0, 0))

                # –í—ã—á–∏—Å–ª—è–µ–º –ø–æ–∑–∏—Ü–∏—é –¥–ª—è –∏–¥–µ–∞–ª—å–Ω–æ–≥–æ —Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∏—è
                paste_position = (
                    (self.target_size[0] - img_copy.width) // 2,
                    (self.target_size[1] - img_copy.height) // 2
                )

                # –í—Å—Ç–∞–≤–ª—è–µ–º –æ—Ç–º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞ —á–µ—Ä–Ω—ã–π —Ñ–æ–Ω
                background.paste(img_copy, paste_position)
                
                # –ü—Ä–∏–º–µ–Ω—è–µ–º –Ω–µ–±–æ–ª—å—à–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –∫ —Ñ–∏–Ω–∞–ª—å–Ω–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
                enhancer = ImageEnhance.Contrast(background)
                final_image = enhancer.enhance(1.1)
                enhancer = ImageEnhance.Sharpness(final_image)
                final_image = enhancer.enhance(1.1)

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Ç–æ–≥–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                final_image.save(output_path, 'JPEG', quality=90, optimize=True)
                
                logger.info(f"‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ (letterbox): {output_path}")
                return str(output_path)
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (letterbox): {e}", exc_info=True)
            return None
    
    def _download_and_process_gif(self, gif_url: str, news_title: str) -> Optional[str]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ GIF —Ñ–∞–π–ª–∞"""
        try:
            # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
            url_hash = hashlib.md5(gif_url.encode()).hexdigest()[:8]
            safe_title = "".join(c for c in news_title[:20] if c.isalnum() or c in (' ', '-', '_')).strip()
            safe_title = safe_title.replace(' ', '_')
            
            filename = f"{safe_title}_{url_hash}.gif"
            local_path = self.media_dir / filename
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –ª–∏ —É–∂–µ
            if local_path.exists():
                logger.info(f"üìÅ GIF —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {local_path}")
                return str(local_path)
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º GIF
            logger.info(f"‚¨áÔ∏è –ó–∞–≥—Ä—É–∂–∞–µ–º GIF: {gif_url}")
            response = requests.get(
                gif_url, 
                headers={
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                },
                timeout=30,
                stream=True
            )
            response.raise_for_status()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
            content_length = response.headers.get('Content-Length')
            if content_length and int(content_length) > self.max_file_size:
                logger.warning(f"‚ö†Ô∏è GIF —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π: {content_length} –±–∞–π—Ç")
                return None
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º GIF
            with open(local_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    f.write(chunk)
            
            logger.info(f"‚úÖ GIF –∑–∞–≥—Ä—É–∂–µ–Ω: {local_path}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ GIF –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –∞–Ω–∏–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–º
            if not self._is_animated_gif(str(local_path)):
                logger.info(f"üîç GIF –æ–∫–∞–∑–∞–ª—Å—è —Å—Ç–∞—Ç–∏—á–Ω—ã–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º: {local_path}")
                # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –≤ .png –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
                png_path = local_path.with_suffix('.png')
                try:
                    from PIL import Image
                    with Image.open(local_path) as img:
                        img.save(png_path, 'PNG')
                    local_path.unlink()  # –£–¥–∞–ª—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª
                    logger.info(f"üîÑ –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –≤ PNG: {png_path}")
                    return str(png_path)
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ PNG: {e}")
            
            return str(local_path)
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ GIF {gif_url}: {e}")
            return None
    
    def _download_and_process_video(self, video_url: str, news_title: str) -> Optional[str]:
        """–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π Twitter —á–µ—Ä–µ–∑ yt-dlp"""
        
        # –î–ª—è Twitter/X –≤–∏–¥–µ–æ –ø—Ä–æ–±—É–µ–º yt-dlp, –Ω–æ —Ç–æ–ª—å–∫–æ –¥–ª—è –ø–æ–ª–Ω—ã—Ö URL —Ç–≤–∏—Ç–æ–≤
        if ('twitter.com' in video_url or 'x.com' in video_url) and '/status/' in video_url:
            return self._download_twitter_video_with_ytdlp(video_url, news_title)
        elif 'pbs.twimg.com' in video_url:
            logger.warning("‚ö†Ô∏è –ü—Ä—è–º—ã–µ —Å—Å—ã–ª–∫–∏ Twitter –º–µ–¥–∏–∞ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–π –º–µ—Ç–æ–¥")
            return self._download_video_direct(video_url, news_title)
        
        return self._download_video_direct(video_url, news_title)
    
    def _download_twitter_video_with_ytdlp(self, video_url: str, news_title: str) -> Optional[str]:
        """–°–∫–∞—á–∏–≤–∞–Ω–∏–µ Twitter –≤–∏–¥–µ–æ —á–µ—Ä–µ–∑ yt-dlp"""
        try:
            import subprocess
            import json
            from pathlib import Path
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º tweet ID –∏–∑ URL –¥–ª—è yt-dlp
            if 'pbs.twimg.com' in video_url:
                logger.warning("‚ö†Ô∏è –ü—Ä—è–º–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ Twitter –º–µ–¥–∏–∞ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–∞, –Ω—É–∂–µ–Ω URL —Ç–≤–∏—Ç–∞")
                return None
            
            # –°–æ–∑–¥–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
            safe_title = "".join(c for c in news_title if c.isalnum() or c in (' ', '-', '_')).rstrip()[:50]
            safe_title = safe_title.replace(' ', '_')
            
            output_path = self.media_dir / f"{safe_title}_{hash(video_url) % 1000000}.mp4"
            
            # –ö–æ–º–∞–Ω–¥–∞ yt-dlp —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –æ–ø—Ü–∏—è–º–∏ –¥–ª—è Twitter
            cmd = [
                'yt-dlp',
                '--format', 'best[ext=mp4]/best',  # –õ—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –≤ mp4 –∏–ª–∏ –ª—é–±–æ–µ
                '--output', str(output_path),
                '--no-playlist',
                '--extractor-args', 'twitter:api=syndication',  # –ò—Å–ø–æ–ª—å–∑—É–µ–º syndication API
                '--user-agent', 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
                video_url
            ]
            
            logger.info(f"üîÑ –ü—Ä–æ–±—É–µ–º yt-dlp –¥–ª—è Twitter –≤–∏–¥–µ–æ: {video_url[:50]}...")
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º yt-dlp
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
            
            if result.returncode == 0 and output_path.exists():
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
                try:
                    from moviepy import VideoFileClip
                    with VideoFileClip(str(output_path)) as video_clip:
                        duration = video_clip.duration
                        if duration > self.max_video_duration:
                            logger.warning(f"‚ö†Ô∏è –í–∏–¥–µ–æ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ: {duration}—Å (–º–∞–∫—Å–∏–º—É–º {self.max_video_duration}—Å)")
                            output_path.unlink()
                            return None
                        
                        logger.info(f"‚úÖ Twitter –≤–∏–¥–µ–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ —á–µ—Ä–µ–∑ yt-dlp: {output_path} (–¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {duration:.1f}—Å)")
                        return str(output_path)
                except ImportError:
                    logger.info(f"‚úÖ Twitter –≤–∏–¥–µ–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ —á–µ—Ä–µ–∑ yt-dlp: {output_path}")
                    return str(output_path)
            else:
                logger.warning(f"‚ö†Ô∏è yt-dlp –Ω–µ —Å–º–æ–≥ –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤–∏–¥–µ–æ: {result.stderr}")
                return None
                
        except subprocess.TimeoutExpired:
            logger.error("‚ùå yt-dlp –ø—Ä–µ–≤—ã—Å–∏–ª –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è (60—Å)")
            return None
        except FileNotFoundError:
            logger.warning("‚ö†Ô∏è yt-dlp –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install yt-dlp")
            return None
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ yt-dlp –¥–ª—è Twitter –≤–∏–¥–µ–æ: {e}")
            return None
    
    def _download_video_direct(self, video_url: str, news_title: str) -> Optional[str]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ–±–æ–ª—å—à–æ–≥–æ –≤–∏–¥–µ–æ —Ñ–∞–π–ª–∞"""
        try:
            # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
            url_hash = hashlib.md5(video_url.encode()).hexdigest()[:8]
            safe_title = "".join(c for c in news_title[:20] if c.isalnum() or c in (' ', '-', '_')).strip()
            safe_title = safe_title.replace(' ', '_')
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∏–∑ URL
            from urllib.parse import urlparse
            parsed_url = urlparse(video_url.lower())
            ext = '.mp4'  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
            if '.' in parsed_url.path:
                ext = '.' + parsed_url.path.split('.')[-1]
                if ext not in self.supported_video_formats:
                    ext = '.mp4'
            
            filename = f"{safe_title}_{url_hash}{ext}"
            local_path = self.media_dir / filename
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –ª–∏ —É–∂–µ
            if local_path.exists():
                logger.info(f"üìÅ –í–∏–¥–µ–æ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {local_path}")
                return str(local_path)
            
            # –°–Ω–∞—á–∞–ª–∞ –ø–æ–ª—É—á–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä–∞–∑–º–µ—Ä–∞
            logger.info(f"üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä –≤–∏–¥–µ–æ: {video_url}")
            head_response = requests.head(
                video_url,
                headers={
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                },
                timeout=10
            )
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
            content_length = head_response.headers.get('Content-Length')
            if content_length and int(content_length) > self.max_video_size:
                logger.warning(f"‚ö†Ô∏è –í–∏–¥–µ–æ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–µ: {content_length} –±–∞–π—Ç (–º–∞–∫—Å–∏–º—É–º {self.max_video_size})")
                return None
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–∏–¥–µ–æ
            logger.info(f"‚¨áÔ∏è –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–∏–¥–µ–æ: {video_url}")
            response = requests.get(
                video_url, 
                headers={
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                },
                timeout=60,  # –ë–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –≤–∏–¥–µ–æ
                stream=True
            )
            response.raise_for_status()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–∏–¥–µ–æ
            with open(local_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    f.write(chunk)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤–∏–¥–µ–æ —Å –ø–æ–º–æ—â—å—é MoviePy
            try:
                from moviepy import VideoFileClip
                with VideoFileClip(str(local_path)) as video_clip:
                    duration = video_clip.duration
                    if duration > self.max_video_duration:
                        logger.warning(f"‚ö†Ô∏è –í–∏–¥–µ–æ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ: {duration}—Å (–º–∞–∫—Å–∏–º—É–º {self.max_video_duration}—Å)")
                        local_path.unlink()  # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª
                        return None
                    
                    # –°–æ–∑–¥–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–∏–¥–µ–æ –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
                    video_info = {
                        'path': str(local_path),
                        'duration': duration,
                        'needs_trimming': duration > self.target_short_duration,
                        'suggested_trim_duration': min(duration, self.target_short_duration)
                    }
                    
                    if duration > self.target_short_duration:  # –ï—Å–ª–∏ –≤–∏–¥–µ–æ –¥–ª–∏–Ω–Ω–µ–µ —Ü–µ–ª–µ–≤–æ–π –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                        logger.info(f"‚úÖ –í–∏–¥–µ–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {local_path} (–¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {duration:.1f}—Å) - –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–∞—á–∞–ª—å–Ω—ã–µ {video_info['suggested_trim_duration']}—Å –¥–ª—è —à–æ—Ä—Ç—Å–∞")
                    else:
                        logger.info(f"‚úÖ –í–∏–¥–µ–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {local_path} (–¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {duration:.1f}—Å)")
                    
                    return str(local_path)
                    
            except ImportError:
                logger.warning("MoviePy –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤–∏–¥–µ–æ")
                logger.info(f"‚úÖ –í–∏–¥–µ–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {local_path}")
                return str(local_path)
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤–∏–¥–µ–æ {video_url}: {e}")
            # –£–¥–∞–ª—è–µ–º —á–∞—Å—Ç–∏—á–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            if 'local_path' in locals() and local_path.exists():
                local_path.unlink()
            return None
    
    def get_background_music(self) -> Optional[str]:
        """–í—ã–±–∏—Ä–∞–µ—Ç —Å–ª—É—á–∞–π–Ω—ã–π —Ç—Ä–µ–∫ –∏–∑ –ø–∞–ø–∫–∏ —Å –º—É–∑—ã–∫–æ–π."""
        music_dir = Path("resources/music")
        
        if not music_dir.exists():
            logger.warning("üìÅ –ü–∞–ø–∫–∞ resources/music –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return None
        
        # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –∞—É–¥–∏–æ —Ñ–æ—Ä–º–∞—Ç—ã
        audio_extensions = ['.mp3', '.wav', '.ogg', '.m4a']
        
        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –∞—É–¥–∏–æ—Ñ–∞–π–ª—ã
        music_files = []
        for ext in audio_extensions:
            music_files.extend(music_dir.glob(f"*{ext}"))
        
        if not music_files:
            logger.warning("üéµ –§–æ–Ω–æ–≤–∞—è –º—É–∑—ã–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return None
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–µ—Ä–≤—ã–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π —Ñ–∞–π–ª (–º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å —Å–ª—É—á–∞–π–Ω—ã–π –≤—ã–±–æ—Ä)
        selected_music = music_files[0]
        logger.info(f"üéµ –í—ã–±—Ä–∞–Ω–∞ —Ñ–æ–Ω–æ–≤–∞—è –º—É–∑—ã–∫–∞: {selected_music.name}")
        
        return str(selected_music)
    
    def cleanup_old_media(self, days_old: int = 7):
        """–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –º–µ–¥–∏–∞-—Ñ–∞–π–ª–æ–≤"""
        try:
            import time
            current_time = time.time()
            cutoff_time = current_time - (days_old * 24 * 60 * 60)
            
            cleaned_count = 0
            for file_path in self.media_dir.glob("*"):
                if file_path.is_file() and file_path.stat().st_mtime < cutoff_time:
                    file_path.unlink()
                    cleaned_count += 1
            
            if cleaned_count > 0:
                logger.info(f"üßπ –£–¥–∞–ª–µ–Ω–æ {cleaned_count} —Å—Ç–∞—Ä—ã—Ö –º–µ–¥–∏–∞-—Ñ–∞–π–ª–æ–≤")
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –º–µ–¥–∏–∞-—Ñ–∞–π–ª–æ–≤: {e}")
    
    def get_media_info(self, media_path: str) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–µ–¥–∏–∞-—Ñ–∞–π–ª–µ"""
        try:
            path = Path(media_path)
            if not path.exists():
                return {'exists': False}
            
            stat = path.stat()
            
            info = {
                'exists': True,
                'size': stat.st_size,
                'modified': stat.st_mtime,
                'extension': path.suffix.lower()
            }
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            if path.suffix.lower() in self.supported_image_formats:
                try:
                    with Image.open(path) as img:
                        info.update({
                            'width': img.width,
                            'height': img.height,
                            'format': img.format,
                            'mode': img.mode
                        })
                except Exception:
                    pass
            
            return info
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ñ–∞–π–ª–µ {media_path}: {e}")
            return {'exists': False, 'error': str(e)}
    
    def _download_politico_image(self, image_url: str) -> Optional[bytes]:
        """–°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π POLITICO —Å –æ–±—Ö–æ–¥–æ–º –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫"""
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É –∏–∑ POLITICO CDN URL
            if 'dims4/default/resize' in image_url and 'url=' in image_url:
                # –î–µ–∫–æ–¥–∏—Ä—É–µ–º URL –∏–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ url=
                import urllib.parse
                parsed_url = urllib.parse.urlparse(image_url)
                query_params = urllib.parse.parse_qs(parsed_url.query)
                if 'url' in query_params:
                    direct_url = urllib.parse.unquote(query_params['url'][0])
                    logger.info(f"üîó –ò–∑–≤–ª–µ—á–µ–Ω–∞ –ø—Ä—è–º–∞—è —Å—Å—ã–ª–∫–∞ POLITICO: {direct_url}")
                    
                    # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É —Å POLITICO headers
                    headers = {
                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                        'Referer': 'https://www.politico.com/',
                        'Accept': 'image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8',
                        'Accept-Language': 'en-US,en;q=0.9',
                        'Accept-Encoding': 'gzip, deflate, br',
                        'Connection': 'keep-alive',
                        'Upgrade-Insecure-Requests': '1'
                    }
                    
                    response = requests.get(direct_url, headers=headers, timeout=10)
                    if response.status_code == 200:
                        logger.info(f"‚úÖ POLITICO –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {len(response.content)} –±–∞–π—Ç")
                        return response.content
                    else:
                        logger.warning(f"‚ö†Ô∏è –ü—Ä—è–º–∞—è —Å—Å—ã–ª–∫–∞ POLITICO –≤–µ—Ä–Ω—É–ª–∞ {response.status_code}")
                        
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ POLITICO –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
            
        return None
    
    def _download_lemonde_image(self, image_url: str) -> Optional[bytes]:
        """–°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π Le Monde —Å –æ–±—Ö–æ–¥–æ–º –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫"""
        try:
            # Le Monde –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ headers –¥–ª—è –∑–∞—â–∏—Ç—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Referer': 'https://www.lemonde.fr/',
                'Accept': 'image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8',
                'Accept-Language': 'en-US,en;q=0.9,fr;q=0.8',
                'Accept-Encoding': 'gzip, deflate, br',
                'Connection': 'keep-alive',
                'Sec-Fetch-Dest': 'image',
                'Sec-Fetch-Mode': 'no-cors',
                'Sec-Fetch-Site': 'same-site'
            }
            
            response = requests.get(image_url, headers=headers, timeout=10)
            if response.status_code == 200:
                logger.info(f"‚úÖ Le Monde –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {len(response.content)} –±–∞–π—Ç")
                return response.content
            else:
                logger.warning(f"‚ö†Ô∏è Le Monde –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤–µ—Ä–Ω—É–ª–æ {response.status_code}")
                        
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Le Monde –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
            
        return None
    
    def _download_with_retry(self, url: str, max_attempts: int = 3):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ —Å retry –º–µ—Ö–∞–Ω–∏–∑–º–æ–º –∏ —Ä–∞–∑–Ω—ã–º–∏ User-Agent"""
        import random
        import time
        
        for attempt in range(max_attempts):
            try:
                # –°–æ–∑–¥–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏
                headers = {
                    'User-Agent': random.choice(self.user_agents),
                    'Accept': 'image/avif,image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8',
                    'Accept-Language': 'en-US,en;q=0.9,ru;q=0.8',
                    'Accept-Encoding': 'gzip, deflate, br',
                    'DNT': '1',
                    'Connection': 'keep-alive',
                    'Upgrade-Insecure-Requests': '1',
                    'Sec-Fetch-Dest': 'image',
                    'Sec-Fetch-Mode': 'no-cors',
                    'Sec-Fetch-Site': 'cross-site',
                    'Cache-Control': 'max-age=0'
                }
                
                # –î–æ–±–∞–≤–ª—è–µ–º Referer –¥–ª—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —Å–∞–π—Ç–æ–≤
                if 'politico.com' in url.lower():
                    headers['Referer'] = 'https://www.politico.com/'
                elif any(domain in url.lower() for domain in ['cnn.com', 'bbc.com', 'reuters.com']):
                    headers['Referer'] = 'https://www.google.com/'
                
                if attempt > 0:
                    time.sleep(2)  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –ø–æ–ø—ã—Ç–∫–∞–º–∏
                    logger.info(f"üîÑ –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1} –∑–∞–≥—Ä—É–∑–∫–∏: {url[:50]}...")
                
                response = requests.get(
                    url,
                    headers=headers,
                    timeout=30,
                    stream=True,
                    allow_redirects=True
                )
                
                response.raise_for_status()
                return response
                
            except requests.exceptions.HTTPError as e:
                if e.response.status_code == 403:
                    logger.warning(f"‚ö†Ô∏è 403 Forbidden –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ {attempt + 1} –¥–ª—è {url[:50]}...")
                    if attempt == max_attempts - 1:
                        logger.error(f"‚ùå –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –∑–∞–≥—Ä—É–∑–∫–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã –¥–ª—è {url}")
                        return None
                    continue
                else:
                    logger.error(f"‚ùå HTTP –æ—à–∏–±–∫–∞ {e.response.status_code} –¥–ª—è {url}: {e}")
                    return None
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ {attempt + 1} –¥–ª—è {url}: {e}")
                if attempt == max_attempts - 1:
                    logger.error(f"‚ùå –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –∑–∞–≥—Ä—É–∑–∫–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã –¥–ª—è {url}")
                    return None
                continue
        
        return None
    
    def _download_with_selenium(self, image_url: str, existing_driver=None) -> Optional[bytes]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ Selenium –¥–ª—è –æ–±—Ö–æ–¥–∞ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫"""
        try:
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º Selenium –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
            from selenium import webdriver
            from selenium.webdriver.chrome.options import Options
            from selenium.webdriver.common.by import By
            import time
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π driver –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω, –∏–Ω–∞—á–µ —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π
            if existing_driver:
                driver = existing_driver
                should_quit = False
            else:
                # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Chrome –¥–ª—è —Å–∫—Ä—ã—Ç–æ–π —Ä–∞–±–æ—Ç—ã
                chrome_options = Options()
                chrome_options.add_argument("--headless")
                chrome_options.add_argument("--no-sandbox")
                chrome_options.add_argument("--disable-dev-shm-usage")
                chrome_options.add_argument("--disable-gpu")
                chrome_options.add_argument("--disable-images")  # –ü–∞—Ä–∞–¥–æ–∫—Å–∞–ª—å–Ω–æ, –Ω–æ –ø–æ–º–æ–≥–∞–µ—Ç –∏–∑–±–µ–∂–∞—Ç—å –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫
                chrome_options.add_argument("--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
                
                driver = webdriver.Chrome(options=chrome_options)
                should_quit = True
            
            try:
                # –ï—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π driver, –Ω–µ –ø–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ –¥—Ä—É–≥—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
                # –î–ª—è POLITICO –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∑–∞–≥—Ä—É–∂–∞–µ–º –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                if not existing_driver:
                    # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º —Ç–æ–ª—å–∫–æ –¥–ª—è –Ω–æ–≤–æ–≥–æ driver
                    driver.get(image_url)
                    time.sleep(3)  # –î–∞–µ–º –≤—Ä–µ–º—è –∑–∞–≥—Ä—É–∑–∏—Ç—å—Å—è
                
                # –ü–æ–ª—É—á–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–∞–∫ base64 —á–µ—Ä–µ–∑ JavaScript
                script = """
                var canvas = document.createElement('canvas');
                var ctx = canvas.getContext('2d');
                var img = new Image();
                img.crossOrigin = 'anonymous';
                
                return new Promise((resolve) => {
                    img.onload = function() {
                        canvas.width = img.width;
                        canvas.height = img.height;
                        ctx.drawImage(img, 0, 0);
                        resolve(canvas.toDataURL('image/jpeg', 0.8).split(',')[1]);
                    };
                    img.onerror = function() { resolve(null); };
                    img.src = arguments[0];
                });
                """
                
                base64_data = driver.execute_async_script(script, image_url)
                
                if base64_data:
                    # –î–µ–∫–æ–¥–∏—Ä—É–µ–º base64 –≤ –±–∞–π—Ç—ã
                    image_bytes = base64.b64decode(base64_data)
                    logger.info(f"‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ —á–µ—Ä–µ–∑ Selenium: {len(image_bytes)} –±–∞–π—Ç")
                    return image_bytes
                else:
                    logger.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —á–µ—Ä–µ–∑ JavaScript")
                    return None
                    
            finally:
                if should_quit:
                    driver.quit()
                
        except ImportError:
            logger.warning("‚ö†Ô∏è Selenium –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
            return None
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —á–µ—Ä–µ–∑ Selenium: {e}")
            return None
